---
title: Resume Framework
author: "Misty"
tags: ["Study map","Job"]
categories: ["Study Map"]
date: 2021-06-19
---


## Database

### sql基础知识

[sql基础知识](https://www.m1sty.com/2020/database_sql_notes/)

### sql笔试题

[SQL面试必会50题](https://www.m1sty.com/2020/database_sql_50/)

```sql
# 查询每门功成绩最好的前两名
SELECT c_id, 
max(case when rank1 = 1 then s_score else null end ) as '第一',
max(case when rank1 = 2 then s_score else null end ) as '第二'
FROM (SELECT score.s_id, student.s_name, score.c_id, score.s_score, row_number() over(partition by c_id order by s_score DESC) rank1
FROM score 
INNER JOIN student
ON score.s_id = student.s_id) a
WHERE rank1 in (1,2)
Group by c_id;
```

```sql
# 查询选修“张三”老师所授课程的学生中成绩最高的学生姓名及其成绩
select score.s_id, s_name, s_score
from score
inner join student
on score.s_id = student.s_id
inner join course
on score.c_id = course.c_id
inner join teacher
on teacher.t_id = course.t_id
where t_name = '张三'
order by s_score desc
limit 1 offset 1
```

## 统计学

### 核心知识
* [统计学考点](https://www.m1sty.com/2021/note_statistics/)

### AB Test
* [AB Test业务知识](https://www.m1sty.com/2021/note_operational-issues/#ab%E5%AE%9E%E9%AA%8C)
* [AB Test实验全知识+统计学](https://www.m1sty.com/2021/business_web_ab-test/)

## 项目相关

### 项目介绍

* 预测布料利用率->嵌入公司报价系统，实现自动报价，节约人力资源和时间成本
* 构建正品率指标体系->监控异常生产数据，建立循环改善机制，优化生产流程，提升正品率
* 数据获取->数据处理->建模处理->模型优化->可视化呈现->指标体系

### 数据来源

* 生产系统（自动生成/手工录入）：布料系统/样式系统/车缝系统/对条对格系统/烫/水洗系统/染色系统……
* 取出后导入数据库/处理/筛选（excel/sql/python）

### 因子筛选

* 建模前
    * 预处理
        * 选择子集
        * 重命名列
        * 缺失数据处理
        * 数据类型的转换
        * 字符串的处理
        * 时间日期的处理
        * 数据排序
        * 异常值处理
            * 数据缺失
            * 数据噪声
            * 数据不一致
            * 数据冗余
            * 离群点/异常值（IQR 定义异常数）
            * 数据重复是在数据集中出现多次的数据
    * 根据生产流程找到关键指标
    * 分组分析（种类/工厂）
    * 降维（PCA）

* 建模后
    * 相关性分析
        * 因子拆分（相关系数大/包含内容多）
        * 因子细化（相关系数小/包含内容少）
        * 因子删除
    * 聚类分析，观察
    * 因子分组实验

### 模型选择

* 随机森林模型
* Ridge回归模型
* Lasso回归模型

### 模型比较

* 均方误差
* 拟合优度

### 如何优化

* 建模
    * Xgboost
    * 模型比较方式：ROC曲线（分类）
* 数据
    * 核心指标拆解（对核心指标进行公式计算，再从不同的生产路径进行拆解）
    * 指标的周知、存档及落地

### 成果产出

* 数据规范（降低数据处理时间，数据良性循环）
* 模型预测准确率，提升收益（时间成本/人力成本）
* 生产流程优化，提升正品率
* 项目推广

### 汇报阶段
* 如何分组分类，因子来源
* 模型选择，判定标准
* 指标体系建立
* 优化效果，因子组合，嵌入系统的可行性

### 项目成员

* 智能制造，精益生产，项目
* 预测报价->核心指标->提升正品率->指标体系
* 数据选取、实验设计、模型调优、指标搭建、项目上线等

### 困难

* 数据理解
* 模型原理

### 实体产业数据分析和互联网区别

* 数据
    * 质量差（人工填写），错误/缺失高
    * 标准化程度低，车间之间、工厂之间缺乏统一标准
* 建模
    * 模型更复杂
    * 规则不明显
* 指标体系
    * 核心指标大多为原生指标，派生指标待探究
    * 以业务为导向，比较平面和抽象，没有例如AAARR这样的模型可以使用
    * 推进指标体系的思想比较困难（指标的周知、存档及落地）

## 技术相关

### 随机森林模型

[随机森林模型](https://www.m1sty.com/2021/dm_decistion-trees_5_practise/#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E6%80%9D%E6%83%B3)

* 决策树节点字段的选择和阈值的选择:信息增益/信息增益率/基尼指数
* 分类树和回归树
    * 分类树使用信息增益或增益比率来划分节点；每个节点样本的类别情况投票决定测试样本的类别。
    * 回归树使用最大均方差划分节点；每个节点样本的均值作为测试样本的回归预测值。
* 随机森林模型介绍
    * 利用Bootstrp抽样法，从原始数据集合中生成k个数据集，并且每个数据集都含有N个观测和P个自变量；
    * 针对每一个数据集，构造一棵CART决策树，在构建子树的过程中，并没有将所有自变量用作节点字段的选择，而是随机选择p个字段；
    * 让每一棵决策树尽可能地充分生长，使得树中的每个节点尽可能“纯净”，即随机森林中的每一棵子树都不需要剪枝；
    * 针对k棵CART树的随机森林，对分类问题利用投票法，将最高得分的类别用于最终的判断结果；对回归问题利用均值法，将其用作预测样本的最终结果。


### 线性回归模型
* 相关性分析
![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210402115124.png)

* 偏回归系数
![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210402121356.png)

![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210402121412.png)

### Ridge回归模型和Lasso回归模型

* 线性回归模型的短板
![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210408191356.png)

* Ridge回归模型：为解决多元线性回归模型中可能存在的不可逆问题，统计学家提出了岭回归模型。该模型解决问题的思路就是在线性回归模型的目标函数之上增加l2正则项（也称为惩罚项）。

![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210408192153.png)

* 岭回归模型解决线性回归模型中矩阵X’X不可逆的办法是添加l2正则的惩罚项,但缺陷在于始终保留建模时的所有变量,无法降低模型的复杂度。对于此, Lasso回归采用了l1正则的惩罚项。

![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210408194118.png)

* 构建Lambda->交叉验证->模型拟合->最佳Lambda->基于最佳的Lambda值建模->返回岭回归系数->预测->验证

* 交叉验证
![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210408192933.png)

* 对比优劣
    * [几种常见回归算法的原理和优劣对比](https://www.zhoulujun.cn/html/theory/algorithm/RegressionAlgorithm/8272.html)


### 对比建模结果

* ROC 
    * ROC的全称是Receiver Operating Characteristic Curve，中文名字叫“受试者工作特征曲线”，顾名思义，其主要的分析方法就是画这条特征曲线。
    * 该曲线的横坐标为假阳性率（False Positive Rate, FPR），N是真实负样本的个数，FP是N个负样本中被分类器预测为正样本的个数。
    * 纵坐标为真阳性率（True Positive Rate, TPR），P是真实正样本的个数，TP是P个正样本中被分类器预测为正样本的个数。
    * AUC（Area under roc Curve）面积，就是指ROC曲线下的面积大小，而计算AUC值只需要沿着ROC横轴做积分就可以了。真实场景中ROC曲线一般都会在y=x这条直线的上方，所以AUC的取值一般在0.5~1之间。AUC的值越大，说明该模型的性能越好。

* 均方误差
    * 均方误差：是预测值与真实值之差的平方和的平均值（衡量预测结果）
    * 均方差/标准差：是方差的算术平方根。而方差是样本实际值与实际值的总体平均值之差的平方和的平均值。（衡量数据集的离散程度）

* 拟合优度
    * 回归分析中用来检验样本数据点聚集在回归线周围的密集程度，用于评价回归方程对样本观测值的拟合程度。
    * 过拟合定义：模型在训练集上的表现很好，但在测试集和新数据上的表现很差。
    * 产生过拟合的原因：
        * 模型复杂度过高，参数过多
        * 训练数据比较小
        * 训练集和测试集分布不一致（样本里面的噪声数据干扰过大，导致模型过分记住了噪声特征，反而忽略了真实的输入输出特征/训练集和测试集特征分布不一样，如果训练集和测试集使用了不同类型的数据集会出现这种情况）
    * 过拟合的解决办法：
        * 降低模型复杂度
        * 增加更多数据
        * 数据增强（使用数据增强可以生成多幅相似图像。这可以帮助我们增加数据集规模从而减少过拟合。因为随着数据量的增加，模型无法过拟合所有样本，因此不得不进行泛化。计算机视觉领域通常的做法有：翻转、平移、旋转、缩放、改变亮度、添加噪声等等，音频数据增强方法有：增加噪音、增加混响、时移、改变音调和时间拉伸）
        * 正则化
            * L1惩罚项的目的是使权重绝对值最小化
            * L2惩罚项的目的是使权重的平方最小化
![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/20210409123032.png)


### 聚类分析

* k-means
    * K-means聚类算法利用距离远近的思想将目标数据为制定的k个簇，进而使样本呈现簇内差异小，簇间差异大的特征。（簇内样本的离差平方和之和达到最小）
    * 最佳k选择：拐点法。在不同的k值下计算簇内利差平方和，然后通过可视化的方法找到“拐点”所对应的k值。当折线图中的斜率由大突然变小时，并且之后的斜率变化缓慢，则认为突然变化的点就是寻找的目标点，因为继续随着簇数k的增加，聚类效果不再有大的变化。
* DBSCAN
    * Kmeans聚类存在两个致命缺点，一是聚类效果容易受到异常样本点的影响;二是该算法无法准确地将非球形样本进行合理的聚类。
    * 基于密度的聚类则可以解决非球形簇的问题，“密度”可以理解为样本点的紧密程度，如果在指定的半径领域内，实际样本量超过给定的最小样本量阈值，则认为是密度高的对象，就可以聚成一个簇。
* 层次聚类
    * 层次聚类更适合小样本；K-Means更适合大样本。
* [用户画像](https://www.m1sty.com/2021/note_operational-issues/#%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F)

### 关联规则

* 支持度
* 置信度
* 频繁项集
* 关联规则

### Tableau
* 制作可交互、数据集成的仪表板
* 展现建模结果，对比建模效果
* 及时发现问题，做出决策支持

### 分类算法

* 朴素贝叶斯分类器（Naive Bayes）
* 支持向量机（SVM）
* K-最邻近（K-Nearest Neighbor）
* 逻辑斯谛回归（Logistic regression）
* 决策树（Decision trees）
* 神经网络（Neural networks）
* 主题模型（LDA）

### 分类、回归分析、时间序列分析、主成分分析等分析方法，应用场景和方法
* 分类
    * 分类明确，数目和特征都明确
    * 业务场景：是否会购买某样东西
    * 常见算法：逻辑回归、SVM、决策树
* 回归
    * 我和你有没有关系？有关系的话是什么关系？关系有多深？
    * 业务场景：优惠券的优惠力度对促活跃的效果/运营推广中，是不是花的钱越多，买的流量越大，品类越丰富，用户活跃越高，用户留存越高/那么，多到什么程度、大到什么程度、丰富到什么程度，用户的活跃最高，留存最高
    * 常见算法：线性回归（什么是线性？导数为常数）
* 时间序列
    * 核心逻辑：江山易改本性难移
    * 对不同周期的数据进行加权，离现在越近的数据权重越高，越远权重越低。
    * 周期性、季节性
    * 回归预测和时间序列预测的区别：回归是是自变量对因变量的预测，自变量可以是任何数据（包括时间），但无法做季节性预测；时间序列只考量时间对的因变量的影响，有季节性。
* 主成分分析
    * 主成分分析的主要目的是用较少的变量去解释原来数据中的大部分信息，将许多相关性较高的变量转化为彼此相互独立和不相干的变量。除了调用PCA(n_components=k).fit_transform(data)一股脑的将数据进行压缩降维，主成分分析还能用于很多地方。
    * 对指标进行建模时的客观赋权
    * 构造新特征
    * 进行特征选项 / 对特征重要性进行排序
    * 异常数据检测
    * [用户生命周期价值](https://www.m1sty.com/2021/note_operational-issues/#%E7%94%A8%E6%88%B7%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E4%BB%B7%E5%80%BC)


## 商业相关

### 商业智能

[商业智能](https://www.m1sty.com/2021/note_bi_map/)


### 业务场景

[分析场景](https://www.m1sty.com/2021/note_operational-issues/)
[运营场景](https://www.m1sty.com/2021/note_industry-and-business-scenarios/)
[店铺分析](https://www.m1sty.com/2021/note_shop-analysis/)

### MECE原则

[梳理业务与指标](https://www.m1sty.com/2021/project_data-index_content/#%E6%A2%B3%E7%90%86%E4%B8%9A%E5%8A%A1%E4%B8%8E%E6%8C%87%E6%A0%87)

### 数据指标体系

[指标体系](https://www.m1sty.com/2021/note_operational-issues/#%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB)

[搭建数据指标体系（项目）](https://www.m1sty.com/2021/project_data-index_content/)

![](https://raw.githubusercontent.com/M1styDay/image_hosting/master/hugo_images/%E5%9B%BE%E7%89%87%201.png)

### 分析指标的变化
* 描述性统计：下跌了多少？
* 观察变化：同比？环比？
* 评估变化/方差分析：跌幅是否在合理范围？
* 交叉分析/相关性分析：有哪些指标可能和日活下跌有关系，有关系到什么程度？
    * 链路分析（用户路径）
    * 指标拆解（用户群）
* 业务分析：这些指标的运营部门？他们是否有某些运营策略或者活动对造成了这些指标的变化，间接导致日活下跌
* 回归分析/预测：还会跌几天？跌幅最坏去到什么程度
* 风险/损失评估：日活下跌对产品的核心kpi有什么影响
* 制定策略：如何挽回损失/如何下次避免

### 面试实例
* 分析某次大促的预计目标是否达成/策略是否有效/对未来的借鉴
* 如何评估红包活动的有效性
* 双十一从以前的一天，变成现在的半个月，拉长了时间线，分析一下战略层这么做的原因是什么？以及如何评估这个活动的效果？

## 个人相关

### 自我介绍

姓名学历专业+工作经历+为什么应聘这个岗位(说明优势及胜任这个岗位的理由，主要针对JD和职位要求)

### 相关课程

* 数据获取（数据库原理/高级数据库管理）
* 数据分析/挖掘（管理统计学/商务智能/数据挖掘）
* 商业思维（数据技术与商业模型分析/数据赋能）

### 本科->工作->研究生

* 了解原理，产生兴趣
* 代码能力，数据理解
* 分析原理，商业思维（先进理念）

### 为什么选择这个专业/读研/全职工作？
* 数据分析方向
* 提升硬核分析能力（工业生产与互联网区别）
* 与商业结合，先进理念、思想、模型

### 职业规划
* 专题分析->分析方法，贴合业务
* 数据指标体系->全局统筹，部门合作
* 数字产品、数字服务->数据驱动业务
* 资深数据分析师->方法论，各业务、部门，中流砥柱

## 待优化

* 统计学核心知识
* hive/hadoop
* Xgboost
* 随机森林模型深挖
* 特征工程
* 项目/场景
    * 请举例说明自己参与的一个数据分析项目
    * 在这个项目中你做了什么?
    * 遇到的困难是怎么解决的?
    * STAR原则（情景/目标/行动/结果）
    * 分析维度有哪些?
    * 用了哪些分析方法?
    * 分析得出哪些结论?
    * 提出了哪些有效的建议?
    * 达到了什么样的效果?
* 关于每个阶段层次的行为（比如说辞职之后到开学之前在干啥，在香港的时间干了些啥吧啦吧啦）
* 前公司老板、同事对你的评价，你对他们的评价
* 假设我是一个不懂数据模型的人，给我讲解一下随机森林模型、ROC曲线
* 多重共线性的解决方法
* 本科时期的项目，做了什么，遇到什么困难的事情怎么解决？（多从自身成长出发）